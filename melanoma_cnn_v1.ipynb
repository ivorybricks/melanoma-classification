{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnnEmQe-oEQ1"
   },
   "source": [
    "# Melanoma CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6JSNk06oEQ2"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVOJq-ptoEQ3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import PIL\n",
    "\n",
    "from tempfile import TemporaryFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "os.sys.path\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/leslie/code/melanoma_files/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['sex', 'anatom_site_general_challenge',\n",
    "                    'benign_malignant','diagnosis', 'age_approx']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, create list of unique patient numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"patient_id\"] = pd.to_numeric(df[\"patient_id\"].str[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patients = set()\n",
    "\n",
    "for index in range(len(df)):\n",
    "    unique_patients.add(df[\"patient_id\"].iloc[index])\n",
    "    \n",
    "unique_patients = list(unique_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use unique patient_id list to split into train and test so that images from the same patients don't end up in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(unique_patients)\n",
    "train_size = int(round(len(unique_patients)*0.8, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = unique_patients[:train_size]\n",
    "test = unique_patients[train_size:]\n",
    "\n",
    "x_train = df[df[\"patient_id\"].isin(train)]\n",
    "x_test = df[df[\"patient_id\"].isin(test)]\n",
    "\n",
    "# Set aside the labels column for train and test sections\n",
    "y_train = x_train.target\n",
    "y_test = x_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filenames = x_train[\"image_name\"].tolist()\n",
    "y_train = y_train.tolist()\n",
    "\n",
    "X_val_filenames = x_test[\"image_name\"].tolist()\n",
    "y_val = y_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create class for a custom generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, image_filenames, labels, batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            cv2.resize(imread('/home/leslie/code/melanoma_files_small/jpeg/train/' + str(file_name) + '.jpg'\n",
    "                         ), (IMG_SIZE, IMG_SIZE)) \n",
    "                for file_name in batch_x])/255.0, np.array(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the training and validation generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(X_train_filenames, y_train, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(X_val_filenames, y_val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model layers and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(  Conv2D(64, (3,3), input_shape = (IMG_SIZE, IMG_SIZE, 3)  )) \n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(  Conv2D(64, (3,3), input_shape = (IMG_SIZE, IMG_SIZE, 3)  ))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "828/828 [==============================] - 178s 215ms/step - loss: 1.1359 - accuracy: 0.9780 - val_loss: 0.0927 - val_accuracy: 0.9803\n",
      "Epoch 2/10\n",
      "828/828 [==============================] - 170s 206ms/step - loss: 0.0950 - accuracy: 0.9818 - val_loss: 0.0917 - val_accuracy: 0.9803\n",
      "Epoch 3/10\n",
      "828/828 [==============================] - 172s 208ms/step - loss: 0.1064 - accuracy: 0.9826 - val_loss: 0.5481 - val_accuracy: 0.9803\n",
      "Epoch 4/10\n",
      "828/828 [==============================] - 174s 210ms/step - loss: 0.0993 - accuracy: 0.9828 - val_loss: 0.0923 - val_accuracy: 0.9803\n",
      "Epoch 5/10\n",
      "828/828 [==============================] - 172s 208ms/step - loss: 0.0854 - accuracy: 0.9829 - val_loss: 0.1329 - val_accuracy: 0.9803\n",
      "Epoch 6/10\n",
      "828/828 [==============================] - 174s 210ms/step - loss: 0.0853 - accuracy: 0.9829 - val_loss: 0.0858 - val_accuracy: 0.9803\n",
      "Epoch 7/10\n",
      "828/828 [==============================] - 172s 207ms/step - loss: 0.0848 - accuracy: 0.9828 - val_loss: 0.0856 - val_accuracy: 0.9803\n",
      "Epoch 8/10\n",
      "828/828 [==============================] - 171s 207ms/step - loss: 0.0842 - accuracy: 0.9831 - val_loss: 0.1020 - val_accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "828/828 [==============================] - 171s 206ms/step - loss: 0.0817 - accuracy: 0.9831 - val_loss: 0.0859 - val_accuracy: 0.9803\n",
      "Epoch 10/10\n",
      "828/828 [==============================] - 171s 207ms/step - loss: 0.0943 - accuracy: 0.9809 - val_loss: 0.0878 - val_accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0f82d2fa0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=my_training_batch_generator,\n",
    "                   steps_per_epoch = int(len(X_train_filenames) // batch_size), \n",
    "                   epochs = 10,\n",
    "                   verbose = 1, #changed verbose from 1 to 2\n",
    "                   validation_data = my_validation_batch_generator,\n",
    "                   validation_steps = int(len(X_val_filenames) // batch_size)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leslie/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /home/leslie/code/melanoma_models/cnn_400/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/home/leslie/code/melanoma_models/cnn_400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/home/leslie/code/melanoma_models/cnn_400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create generator class for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, image_filenames, batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            cv2.resize(imread('/home/leslie/code/melanoma_files_small/jpeg/test/' + str(file_name) + '.jpg'\n",
    "                         ), (IMG_SIZE, IMG_SIZE)) \n",
    "                for file_name in batch_x])/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model to create predictions for test images and export the results as a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/home/leslie/code/melanoma_files/test.csv\")\n",
    "df_test = df_test.drop(columns=['sex', 'anatom_site_general_challenge','age_approx']) \n",
    "\n",
    "IMG_SIZE = 400\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = df_test[\"image_name\"].tolist()\n",
    "my_test_batch_generator = My_Custom_Test_Generator(test_filenames, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(my_test_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(prediction, columns=['target'])\n",
    "df_results[\"image_name\"] = test_filenames\n",
    "\n",
    "columns_titles = [\"image_name\",\"target\"]\n",
    "df_results=df_results.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('/home/leslie/code/melanoma_predictions/results.csv', index = False, header = 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_convnet",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
